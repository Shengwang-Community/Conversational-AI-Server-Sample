# ğŸŒŸ Custom LLm Sample Code for Golang

> å£°ç½‘å¯¹è¯å¼ AI å¼•æ“æ”¯æŒè‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŠŸèƒ½ï¼Œæ‚¨å¯ä»¥å‚è€ƒæ­¤é¡¹ç›®ä»£ç è‡ªå®šä¹‰å®ç°å¤§è¯­è¨€æ¨¡å‹åŠŸèƒ½ã€‚

æœ¬æ–‡æ¡£æ˜¯å®ç°è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹åŠŸèƒ½çš„ Golang ç¤ºä¾‹ä»£ç 

## ğŸš€ ä¸€ã€å¿«é€Ÿå¼€å§‹

### 1.1 ç¯å¢ƒå‡†å¤‡

- Golang 1.21+

### 1.2 å®‰è£…ä¾èµ–

```bash
go mod tidy
```

### 1.3 è¿è¡Œç¤ºä¾‹ä»£ç 

```bash
go run custom_llm.go
```

å½“æœåŠ¡å™¨è¿è¡Œæ—¶ï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼š

```bash
[GIN-debug] Listening and serving HTTP on :8000
```

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•æœåŠ¡å™¨ï¼š

```bash
curl -X POST http://localhost:8000/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_LLM_API_KEY" \
  -d '{"messages": [{"role": "user", "content": "Hello, how are you?"}], "stream": true, "model": "gpt-4o-mini"}'
```

æµ‹è¯•æœåŠ¡å™¨æ—¶ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨å¦‚ [ngrok](https://ngrok.com/) ç­‰éš§é“å·¥å…·å°†æœ¬åœ°æœåŠ¡å™¨æš´éœ²åˆ°äº’è”ç½‘ã€‚

## ğŸ”„ äºŒã€æ¶æ„å’Œæµç¨‹å›¾

### 2.1 ç³»ç»Ÿæ¶æ„

```mermaid
flowchart LR
    Client-->|POST Request|Server

    subgraph Server[Custom LLM Server]
        Basic["chat/completions"]
        RAG["rag/chat/completions"]
        Audio["audio/chat/completions"]
    end


    Server-->|SSE Response|Client

    Server-->|API call|OpenAI[OpenAI API]
    OpenAI-->|Stream Response|Server

    subgraph Knowledge
        KB[Knowledge Base]
    end

    RAG-.->|Retrieval|KB
```

å…³äºä¸‰ä¸ª API æ¥å£ç«¯ç‚¹åŠå…¶è¯·æ±‚æµç¨‹çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜…[è¯·æ±‚æµç¨‹å›¾](#-å››è¯·æ±‚æµç¨‹å›¾)éƒ¨åˆ†ã€‚

## ğŸ“– ä¸‰ã€åŠŸèƒ½è¯´æ˜

### 3.1 åŸºæœ¬çš„è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹

> è¦æˆåŠŸæ¥å…¥å£°ç½‘å¯¹è¯å¼ AI å¼•æ“ï¼Œä½ çš„è‡ªå®šä¹‰å¤§æ¨¡å‹æœåŠ¡å¿…é¡»æä¾›ä¸€ä¸ªä¸ OpenAI Chat Completions API å…¼å®¹çš„æ¥å£ã€‚

`/chat/completions` API ç«¯ç‚¹å®ç°åŸºæœ¬çš„èŠå¤©è¡¥å…¨åŠŸèƒ½ã€‚

### 3.2 å®ç°æ£€ç´¢å¢å¼ºçš„è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹

> å¦‚æœæ‚¨å¸Œæœ›æé«˜ä»£ç†å“åº”çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ï¼Œå¯ä»¥ä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åŠŸèƒ½ã€‚è¿™ä½¿æ‚¨çš„è‡ªå®šä¹‰å¤§æ¨¡å‹èƒ½å¤Ÿä»ç‰¹å®šçŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ï¼Œå¹¶å°†æ£€ç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆã€‚

`/rag/chat/completions` API ç«¯ç‚¹å±•ç¤ºäº†ä½¿ç”¨åŸºäºå†…å­˜çš„çŸ¥è¯†å­˜å‚¨åº“å®ç°çš„ç®€å• RAG åŠŸèƒ½ã€‚

### 3.3 å®ç°å¤šæ¨¡æ€çš„è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹

> å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å¯ä»¥å¤„ç†å’Œç”Ÿæˆæ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘å†…å®¹ã€‚

`/audio/chat/completions` API ç«¯ç‚¹æ¨¡æ‹Ÿå¸¦æœ‰æ–‡æœ¬å’ŒéŸ³é¢‘æ•°æ®å—çš„éŸ³é¢‘å“åº”ã€‚

## ğŸ“ å››ã€è¯·æ±‚æµç¨‹å›¾

### 4.1 åŸºæœ¬çš„å¤§è¯­è¨€æ¨¡å‹è¯·æ±‚æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant Client
    participant Server as Custom LLM Server
    participant OpenAI

    Client->>Server: POST /chat/completions
    Note over Client,Server: With messages, model, stream params

    Server->>OpenAI: Create chat.completions stream

    loop For each chunk
        OpenAI->>Server: Streaming chunk
        Server->>Client: SSE data: chunk
    end

    Server->>Client: SSE data: [DONE]
```

### 4.2 å®ç°æ£€ç´¢å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹è¯·æ±‚æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant Client
    participant Server as Custom LLM Server
    participant KB as Knowledge Base
    participant OpenAI

    Client->>Server: POST /rag/chat/completions
    Note over Client,Server: With messages, model params

    Server->>Client: SSE data: "Waiting message"

    Server->>KB: Perform RAG retrieval
    KB->>Server: Return relevant context

    Server->>Server: Refactor messages with context

    Server->>OpenAI: Create chat.completions stream with context

    loop For each chunk
        OpenAI->>Server: Streaming chunk
        Server->>Client: SSE data: chunk
    end

    Server->>Client: SSE data: [DONE]
```

### 4.3 å¤šæ¨¡æ€éŸ³é¢‘å¤§è¯­è¨€æ¨¡å‹è¯·æ±‚æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant Client
    participant Server as Custom LLM Server
    participant FS as File System

    Client->>Server: POST /audio/chat/completions
    Note over Client,Server: With messages, model params

    alt Files exist
        Server->>FS: Read text file
        FS->>Server: Return text content

        Server->>FS: Read audio file
        FS->>Server: Return audio data

        Server->>Client: SSE data: transcript

        loop For each audio chunk
            Server->>Client: SSE data: audio chunk
            Note over Server,Client: With small delay between chunks
        end
    else Files not found
        Server->>Server: Generate simulated response
        Server->>Client: SSE data: simulated transcript

        loop For simulated chunks
            Server->>Client: SSE data: random audio data
            Note over Server,Client: With small delay between chunks
        end
    end

    Server->>Client: SSE data: [DONE]
```

## ğŸ“š ä¸‰ã€ç›¸å…³èµ„æº

- ğŸ“– æŸ¥çœ‹æˆ‘ä»¬çš„ [å¯¹è¯å¼ AI å¼•æ“æ–‡æ¡£](https://doc.shengwang.cn/doc/convoai/restful/landing-page) äº†è§£æ›´å¤šè¯¦æƒ…
- ğŸ§© è®¿é—® [Agora SDK ç¤ºä¾‹](https://github.com/AgoraIO) è·å–æ›´å¤šæ•™ç¨‹å’Œç¤ºä¾‹ä»£ç 
- ğŸ‘¥ åœ¨ [Agora å¼€å‘è€…ç¤¾åŒº](https://github.com/AgoraIO-Community) æ¢ç´¢å¼€å‘è€…ç¤¾åŒºç®¡ç†çš„ä¼˜è´¨ä»£ç ä»“åº“

## ğŸ’¡ å››ã€é—®é¢˜åé¦ˆ

å¦‚æœæ‚¨åœ¨é›†æˆè¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼š

- ğŸ¤– å¯é€šè¿‡ [å£°ç½‘æ”¯æŒ](https://ticket.shengwang.cn/form?type_id=&sdk_product=&sdk_platform=&sdk_version=&current=0&project_id=&call_id=&channel_name=) è·å–æ™ºèƒ½å®¢æœå¸®åŠ©æˆ–è”ç³»æŠ€æœ¯æ”¯æŒäººå‘˜

## ğŸ“œ äº”ã€è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ (The MIT License)ã€‚